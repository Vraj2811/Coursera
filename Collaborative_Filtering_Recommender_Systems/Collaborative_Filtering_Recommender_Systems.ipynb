{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 22:28:33.997942: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-12 22:28:34.035904: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-12 22:28:34.036729: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 22:28:34.683390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from recsys_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (4778, 10)\n",
      "W (443, 10)\n",
      "b (1, 443)\n",
      "Y (4778, 443)\n",
      "R (4778, 443)\n",
      "num_features 10\n",
      "num_movies 4778\n",
      "num_users 443\n"
     ]
    }
   ],
   "source": [
    "X, W, b, num_movies, num_features, num_users = load_precalc_params_small()\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "print(\"X\", X.shape)\n",
    "print(\"W\", W.shape)\n",
    "print(\"b\", b.shape)\n",
    "print(\"Y\", Y.shape)\n",
    "print(\"R\", R.shape)\n",
    "print(\"num_features\", num_features)\n",
    "print(\"num_movies\",   num_movies)\n",
    "print(\"num_users\",    num_users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Function\n",
    "$$J= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (with regularization): 306504.87\n"
     ]
    }
   ],
   "source": [
    "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
    "\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "\n",
    "    for j in range(nu):\n",
    "        w_j = W[j]\n",
    "        b_j = b[0, j]\n",
    "        for i in range(nm):\n",
    "            x = X[i]\n",
    "            r = R[i, j]\n",
    "            J += r*((np.dot(w_j, x)+b_j-Y[i, j])**2)\n",
    "    J = J/2\n",
    "    J += (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))\n",
    "    return J\n",
    "\n",
    "J = cofi_cost_func(X, W, b, Y, R, 1.5)\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (with regularization): 306504.87\n"
     ]
    }
   ],
   "source": [
    "def cofi_cost_func_vectorized(X, W, b, Y, R, lambda_):\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * \\\n",
    "        (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J\n",
    "\n",
    "J = cofi_cost_func_vectorized(X, W, b, Y, R, 1.5)\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRatings(Y, R):\n",
    "    Ymean = (np.sum(Y*R, axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1, 1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R)\n",
    "    return (Ynorm, Ymean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding My ratings to the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = np.zeros(num_movies)\n",
    "my_ratings[2700] = 5\n",
    "my_ratings[2609] = 2\n",
    "my_ratings[929] = 5\n",
    "my_ratings[246] = 5\n",
    "my_ratings[2716] = 3\n",
    "my_ratings[1150] = 5\n",
    "my_ratings[382] = 2\n",
    "my_ratings[366] = 5\n",
    "my_ratings[622] = 5\n",
    "my_ratings[988] = 3\n",
    "my_ratings[2925] = 1\n",
    "my_ratings[2937] = 1\n",
    "my_ratings[793] = 5\n",
    "\n",
    "Y, R = load_ratings_small()\n",
    "Y = np.c_[my_ratings, Y]\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)\n",
    "num_movies, num_users = Y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 267453.3\n",
      "Training loss at iteration 20: 16320.3\n",
      "Training loss at iteration 40: 9551.2\n",
      "Training loss at iteration 60: 7243.0\n",
      "Training loss at iteration 80: 6215.2\n",
      "Training loss at iteration 100: 5690.9\n",
      "Training loss at iteration 120: 5412.0\n",
      "Training loss at iteration 140: 5251.8\n",
      "Training loss at iteration 160: 5147.2\n",
      "Training loss at iteration 180: 5072.2\n",
      "Training loss at iteration 200: 5015.0\n"
     ]
    }
   ],
   "source": [
    "iterations = 201\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost_value = cofi_cost_func_vectorized(X, W, b, Ynorm, R, lambda_)\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.79\n",
      "Original 5.0, Predicted 4.71\n",
      "Original 2.0, Predicted 2.57\n",
      "Original 5.0, Predicted 4.86\n",
      "Original 5.0, Predicted 4.77\n",
      "Original 5.0, Predicted 4.59\n",
      "Original 3.0, Predicted 3.38\n",
      "Original 5.0, Predicted 4.51\n",
      "Original 2.0, Predicted 2.35\n",
      "Original 5.0, Predicted 4.66\n",
      "Original 3.0, Predicted 3.33\n",
      "Original 1.0, Predicted 1.30\n",
      "Original 1.0, Predicted 1.19\n"
     ]
    }
   ],
   "source": [
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "pm = p + Ymean\n",
    "my_predictions = pm[:, 0]\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
